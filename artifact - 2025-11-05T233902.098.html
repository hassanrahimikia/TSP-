<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>مبانی نظری و پیشینه تحقیق: حل مسئله TSP</title>
    
    <!-- فونت وزیرمتن -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Vazirmatn:wght@300;400;500;700&display=swap" rel="stylesheet">

    <style>
        body {
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            line-height: 1.9;
            margin: 0;
            padding: 0;
            background-color: #f8f9fa;
            color: #212529;
            font-size: 1.1rem;
        }
        header {
            background: linear-gradient(135deg, #2c5364, #203a43, #0f2027);
            color: #ffffff;
            padding: 3rem 2rem;
            text-align: center;
        }
        header h1 {
            margin: 0;
            font-size: 2.8em;
            font-weight: 700;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        header p {
            margin: 10px 0 0;
            font-size: 1.2em;
            color: #e9ecef;
            font-weight: 300;
        }
        main {
            max-width: 900px;
            margin: 3rem auto;
            padding: 0 2rem;
        }
        section {
            background-color: #ffffff;
            margin-bottom: 2.5rem;
            padding: 2rem 2.5rem;
            border-radius: 12px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.08);
            border: 1px solid #dee2e6;
        }
        h2 {
            color: #343a40;
            border-bottom: 3px solid #2c5364;
            padding-bottom: 15px;
            margin-top: 0;
            font-size: 2.2em;
            font-weight: 700;
        }
        h3 {
            color: #495057;
            font-size: 1.6em;
            font-weight: 500;
            margin-top: 2.5rem;
            border-right: 4px solid #adb5bd;
            padding-right: 15px;
        }
        .highlight-box {
            background-color: #eaf4f4;
            border-left: 6px solid #2c5364;
            padding: 20px;
            margin: 2rem 0;
            border-radius: 8px;
        }
        .algorithm-steps ol {
            padding-right: 20px;
            list-style-type: decimal;
        }
        .algorithm-steps li {
            margin-bottom: 15px;
        }
        strong {
            color: #203a43;
        }
        code {
            background-color: #e9ecef;
            color: #c0392b;
            padding: 3px 6px;
            border-radius: 4px;
            font-family: 'Courier New', Courier, monospace;
        }
        footer {
            text-align: center;
            padding: 2rem;
            background-color: #343a40;
            color: #f8f9fa;
            margin-top: 3rem;
        }
    </style>
    
    <!-- پیکربندی MathJax -->
    <script>
        window.MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
          }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

</head>
<body>

    <header>
        <h1>مبانی نظری و پیشینه تحقیق</h1>
        <p>مروری بر روش‌های کلاسیک و مدرن برای حل مسئله فروشنده دوره‌گرد (TSP)</p>
    </header>

    <main>
        <section id="intro-summary">
            <h2>مقدمه‌ای بر رویکردهای حل مسئله</h2>
            <p>
                همانطور که در بخش قبل دیدیم، ماهیت <strong>NP-hard</strong> مسئله فروشنده دوره‌گرد، یافتن راه‌حل بهینه قطعی را برای ابعاد بزرگ مسئله، عملاً غیرممکن می‌سازد. این چالش عظیم باعث شده تا طی دهه‌های گذشته، گستره وسیعی از الگوریتم‌ها و روش‌ها برای مقابله با آن توسعه یابد. این روش‌ها را می‌توان به دو دسته کلی تقسیم کرد: <strong>روش‌های کلاسیک (دقیق و تقریبی)</strong> و <strong>روش‌های مدرن مبتنی بر یادگیری ماشین و شبکه‌های عصبی</strong>. در این بخش، به بررسی مبانی نظری هر دو دسته می‌پردازیم.
            </p>
        </section>

        <section id="classical-methods">
            <h2>بخش اول: رویکردهای کلاسیک</h2>
            <p>این روش‌ها سنگ بنای حل مسائل بهینه‌سازی ترکیبیاتی هستند و درک آن‌ها برای ارزیابی عملکرد روش‌های جدیدتر ضروری است.</p>
            
            <h3>۱. الگوریتم‌های دقیق (Exact Algorithms)</h3>
            <p>
                این الگوریتم‌ها تضمین می‌کنند که در نهایت به کوتاه‌ترین مسیر ممکن دست خواهند یافت. مشکل اصلی آن‌ها، زمان اجرای بسیار طولانی است که به صورت نمایی با تعداد شهرها ($n$) افزایش می‌یابد. معروف‌ترین الگوریتم در این دسته، الگوریتم <strong>Held-Karp</strong> است که از برنامه‌ریزی پویا استفاده می‌کند و دارای پیچیدگی زمانی $O(n^2 2^n)$ می‌باشد. این الگوریتم‌ها عملاً فقط برای مسائل با تعداد شهرهای بسیار کم (معمولاً کمتر از ۲۰) قابل استفاده هستند.
            </p>

            <h3>۲. الگوریتم‌های هیوریستیک و متاهیوریستیک (Heuristics & Metaheuristics)</h3>
            <p>
                از آنجایی که الگوریتم‌های دقیق کارایی لازم را ندارند، تمرکز اصلی محققان بر روی روش‌های تقریبی بوده است. این روش‌ها به دنبال یافتن راه‌حل‌های "به اندازه کافی خوب" در زمانی معقول هستند.
            </p>
            <ul>
                <li><strong>هیوریستیک‌های سازنده (Constructive Heuristics):</strong> این روش‌ها یک تور را از صفر و به صورت مرحله به مرحله می‌سازند. مثال بارز آن الگوریتم <strong>"نزدیک‌ترین همسایه" (Nearest Neighbor)</strong> است که در آن فروشنده از یک شهر شروع کرده و در هر مرحله به نزدیک‌ترین شهر بازدید نشده می‌رود. این روش سریع است اما اغلب به راه‌حل‌های بهینه منجر نمی‌شود.</li>
                <li><strong>هیوریستیک‌های بهبوددهنده (Improvement Heuristics):</strong> این روش‌ها با یک تور اولیه (که ممکن است تصادفی باشد) شروع کرده و سعی در بهبود آن دارند. الگوریتم <strong>2-Opt</strong> یک مثال کلاسیک است. در این روش، دو یال از تور که با هم تلاقی دارند، حذف شده و به شکل دیگری وصل می‌شوند تا تلاقی از بین برود و طول تور کاهش یابد. این فرآیند تا زمانی که هیچ بهبود دیگری ممکن نباشد، تکرار می‌شود.</li>
                <li><strong>متاهیوریستیک‌ها (Metaheuristics):</strong> این‌ها استراتژی‌های سطح بالاتری هستند که الگوریتم‌های هیوریستیک ساده‌تر را هدایت می‌کنند تا از افتادن در دام بهینه‌های محلی (Local Optima) جلوگیری کنند. از جمله معروف‌ترین آن‌ها می‌توان به موارد زیر اشاره کرد:
                    <ul>
                        <li><strong>الگوریتم ژنتیک (Genetic Algorithm):</strong> با الهام از فرآیند تکامل طبیعی، جمعیتی از راه‌حل‌ها (تورها) را ایجاد کرده و با ترکیب (Crossover) و جهش (Mutation) آن‌ها، نسل به نسل راه‌حل‌های بهتری تولید می‌کند.</li>
                        <li><strong>شبیه‌سازی تبرید (Simulated Annealing):</strong> با الهام از فرآیند سرد کردن فلزات، در ابتدا با احتمال بالایی حرکات "بد" (که طول تور را زیاد می‌کنند) را نیز می‌پذیرد تا فضای جستجو را بهتر کاوش کند و به تدریج این احتمال را کاهش می‌دهد.</li>
                        <li><strong>بهینه‌سازی کلونی مورچگان (Ant Colony Optimization):</strong> با الهام از رفتار مورچه‌ها در یافتن مسیر غذا، مسیرهایی که توسط "مورچه‌های مصنوعی" بیشتری طی می‌شوند، با "فرومون" مجازی تقویت شده و به تدریج مسیرهای کوتاه‌تر پدیدار می‌شوند.</li>
                    </ul>
                </li>
            </ul>
        </section>

        <section id="neural-methods">
            <h2>بخش دوم: رویکردهای مبتنی بر شبکه‌های عصبی</h2>
            <p>
                در سال‌های اخیر، شبکه‌های عصبی به عنوان یک پارادایم جدید برای حل مسائل بهینه‌سازی ترکیبیاتی مانند TSP ظهور کرده‌اند. مزیت اصلی این روش‌ها در توانایی "یادگیری" الگوهای ساختاری از داده‌ها و تعمیم آن به مسائل جدید است. در این تحقیق، دو رویکرد برجسته را بررسی می‌کنیم.
            </p>

            <h3>۱. نقشه‌های خودسازمانده (Self-Organizing Maps - SOM)</h3>
            <p>
                نقشه‌های خودسازمانده که توسط <strong>Teuvo Kohonen</strong> معرفی شدند، نوعی شبکه عصبی بدون ناظر (Unsupervised) هستند که برای خوشه‌بندی و کاهش ابعاد داده‌ها استفاده می‌شوند. ایده اصلی استفاده از SOM برای TSP بسیار هوشمندانه است:
            </p>
            <blockquote>
                یک حلقه (Ring) از نورون‌ها را در نظر بگیرید که تعداد آن‌ها برابر با تعداد شهرهاست. این حلقه به صورت تصادفی در فضای دو بعدی شهرها قرار می‌گیرد. سپس در طی یک فرآیند تکرارشونده، این حلقه به تدریج به سمت شهرها "کشیده" می‌شود تا در نهایت شکلی شبیه به کوتاه‌ترین تور ممکن به خود بگیرد.
            </blockquote>
            <div class="algorithm-steps">
                <p>فرآیند یادگیری SOM برای TSP شامل مراحل زیر است:</p>
                <ol>
                    <li><strong>مقداردهی اولیه (Initialization):</strong> نورون‌ها در یک حلقه مرتب شده و وزن‌های آن‌ها (موقعیت مکانی) به صورت تصادفی مقداردهی می‌شوند.</li>
                    <li><strong>رقابت (Competition):</strong> به ازای یک شهر که به صورت تصادفی انتخاب می‌شود، نورونی که به آن شهر نزدیک‌تر است به عنوان "نورون برنده" یا Best Matching Unit (BMU) انتخاب می‌شود.</li>
                    <li><strong>همکاری (Cooperation):</strong> نه تنها نورون برنده، بلکه همسایگان آن در حلقه نیز برای به‌روزرسانی انتخاب می‌شوند. شعاع این همسایگی در ابتدای آموزش بزرگ است و به تدریج کوچک می‌شود.</li>
                    <li><strong>انطباق (Adaptation):</strong> موقعیت (وزن) نورون برنده و همسایگانش به سمت موقعیت شهر انتخاب‌شده حرکت داده می‌شود. میزان این حرکت با نرخ یادگیری کنترل می‌شود که آن هم به تدریج کاهش می‌یابد.</li>
                </ol>
                <p>با تکرار این فرآیند برای تمام شهرها در دوره‌های متعدد، حلقه نورون‌ها به تدریج خود را با توزیع مکانی شهرها تطبیق داده و یک تور معتبر و کوتاه را تشکیل می‌دهد.</p>
            </div>

            <h3>۲. یادگیری تقویتی با شبکه‌های اشاره‌گر (RL with Pointer Networks)</h3>
            <p>
                این رویکرد یکی از مدرن‌ترین و قدرتمندترین روش‌ها برای حل TSP است. در اینجا، مسئله به عنوان یک بازی ترتیبی در چارچوب <strong>یادگیری تقویتی (Reinforcement Learning - RL)</strong> مدل‌سازی می‌شود.
            </p>
            <ul>
                <li><strong>عامل (Agent):</strong> یک شبکه عصبی که یاد می‌گیرد در هر مرحله بهترین شهر بعدی را انتخاب کند.</li>
                <li><strong>محیط (Environment):</strong> مجموعه‌ای از شهرها و وضعیت فعلی (شهرهای بازدید شده).</li>
                <li><strong>عمل (Action):</strong> انتخاب شهر بعدی از میان شهرهای بازدید نشده.</li>
                <li><strong>پاداش (Reward):</strong> در پایان ساخت تور، پاداش برابر با مقدار منفی طول کل تور است. هدف عامل، بیشینه کردن این پاداش (یعنی کمینه کردن طول تور) است.</li>
            </ul>
            <div class="highlight-box">
                <h4>چالش کلیدی: خروجی با اندازه متغیر</h4>
                <p>
                    شبکه‌های عصبی معمولی مانند شبکه‌های بازگشتی (RNN) برای مسائلی مانند ترجمه ماشین طراحی شده‌اند که اندازه دیکشنری کلمات خروجی ثابت است. اما در TSP، لیست شهرهای ممکن برای انتخاب در هر مرحله تغییر می‌کند و به شهرهای ورودی بستگی دارد.
                </p>
                <p>
                    <strong>شبکه‌های اشاره‌گر (Pointer Networks)</strong> برای حل دقیقاً همین مشکل طراحی شده‌اند. این شبکه‌ها به جای نگاشت ورودی به یک خروجی از یک دیکشنری ثابت، یاد می‌گیرند که به یکی از اعضای دنباله ورودی "اشاره" کنند. این مکانیزم برای TSP ایده‌آل است، زیرا در هر مرحله، شبکه مستقیماً به یکی از شهرهای ورودی که هنوز بازدید نشده، اشاره می‌کند.
                </p>
            </div>
            <p>
                ترکیب یادگیری تقویتی با شبکه‌های اشاره‌گر، یک مدل end-to-end ایجاد می‌کند که می‌تواند بدون نیاز به راه‌حل‌های بهینه برای آموزش، مستقیماً از طریق آزمون و خطا و با استفاده از الگوریتم‌هایی مانند Policy Gradient، سیاست (Policy) بهینه‌ای برای ساخت تور پیدا کند.
            </p>
        </section>

        <section id="literature-summary">
            <h2>خلاصه پیشینه و جایگاه تحقیق</h2>
            <p>
                پیشینه تحقیق نشان می‌دهد که الگوریتم‌های متاهیوریستیک کلاسیک مانند LKH (Lin-Kernighan-Helsgaun) همچنان بهترین عملکرد را در یافتن راه‌حل‌های نزدیک به بهینه برای یک نمونه خاص از TSP دارند. با این حال، این روش‌ها نیاز به تنظیمات دقیق پارامترها داشته و زمان اجرای بالایی دارند.
            </p>
            <p>
                از سوی دیگر، روش‌های مبتنی بر یادگیری عمیق، به ویژه مدل‌های مبتنی بر RL و Pointer Networks، این پتانسیل را دارند که یک مدل را یک بار آموزش داده و سپس از آن برای حل سریع نمونه‌های جدید TSP استفاده کنند (توانایی تعمیم). عملکرد این مدل‌ها به سرعت در حال نزدیک شدن به بهترین حل‌کننده‌های کلاسیک است و حوزه تحقیقاتی بسیار فعالی محسوب می‌شود.
            </p>
            <p>
                تحقیق حاضر با پیاده‌سازی و مقایسه دو رویکرد متفاوت از دنیای شبکه‌های عصبی (SOM به عنوان یک روش کلاسیک و الهام‌گرفته از مغز، و RL with Pointer Network به عنوان یک روش مدرن یادگیری عمیق) بر روی یک دیتاست استاندارد (<code>berlin52</code>)، به ارزیابی نقاط قوت و ضعف هر یک در معیارهای مختلفی چون کیفیت راه‌حل، زمان محاسباتی و پایداری می‌پردازد.
            </p>
        </section>
    </main>

    <footer>
        <p>بخش دوم: مبانی نظری و پیشینه تحقیق | تاریخ امروز: ۱۴۰۴/۰۸/۱۴</p>
    </footer>

</body>
</html>
